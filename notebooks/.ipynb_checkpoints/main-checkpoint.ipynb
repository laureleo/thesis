{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "from transformers import AutoModel\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from transformers import AutoTokenizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "# GPU check\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_with_cpu(data_tensor, mask_tensor):\n",
    "    embeddings = model.forward(input_ids=data_tensor,\n",
    "        attention_mask=mask_tensor,\n",
    "        head_mask=None)\n",
    "    print(embeddings[0].shape)\n",
    "\n",
    "    return embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For dealing with large amounts of data, a GPU is much faster\n",
    "\n",
    "The resulting embedding matrix is a three-dimensional tensor corresponding to                 [Sentence][Words][Embeddings]\n",
    "embeddings[5][4][:] is thus the embedding of the fourth word in the fifth sentence\n",
    "\"\"\"\n",
    "\n",
    "def get_embeddings_with_gpu(data_matrix, mask_matrix):\n",
    "    # Load the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #print(f\"Using device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    # Set the model to use the device\n",
    "    model.cuda()\n",
    "\n",
    "    # Move the data onto the GPU\n",
    "    data_matrix = data_matrix.to(device)\n",
    "    mask_matrix = mask_matrix.to(device)\n",
    "\n",
    "    # Generate embeddings\n",
    "    matrix_embedding = model.forward(input_ids=data_matrix,\n",
    "        attention_mask=mask_matrix,\n",
    "        head_mask=None)[0]\n",
    "    #print(f\"Embedding generated with shape {batch_embedding.shape}\")\n",
    "\n",
    "    # Make it an ordinary np array instead of a torch\n",
    "    matrix_embedding = np.array(matrix_embedding.tolist())\n",
    "\n",
    "    return matrix_embedding\n",
    "\n",
    "#Keep amount of samples low to not overwhelm the gpu\n",
    "#get_embeddings_with_gpu(data_tensor_matrix[:10], mask_tensor_matrix[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Most people won't be able to load all the data onto the GPU at once however, so it's better   to do it in batches.\n",
    "(50 input sentences take 2803MB on my computer, for example).\n",
    "\n",
    "This method batchifies and stitches together the batches\n",
    "\"\"\"\n",
    "def get_embeddings_with_gpu_batch(data_matrix, mask_matrix, batch_size):\n",
    "    num_items = data_matrix.shape[0]\n",
    "    num_loops = int(np.ceil(num_items/batch_size))\n",
    "\n",
    "    start = 0\n",
    "    end = batch_size\n",
    "    data_holder = []\n",
    "\n",
    "    for i in trange(num_loops):\n",
    "        # Split the data into batches\n",
    "        data_batch = data_matrix[start:end]\n",
    "        mask_batch = mask_matrix[start:end]\n",
    "\n",
    "        #Get the embedding for the batch\n",
    "        batch_embedding = get_embeddings_with_gpu(data_batch, mask_batch)\n",
    "\n",
    "        data_holder.append(batch_embedding)\n",
    "\n",
    "        #Move to next batch\n",
    "        start += batch_size\n",
    "        end += batch_size\n",
    "\n",
    "    # Merge the batches we've generated\n",
    "    embedding_matrix = np.vstack(data_holder)\n",
    "\n",
    "    print(f\"Final embedding generated with shape {embedding_matrix.shape}\")\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "#embedding_matrix = get_embeddings_with_gpu_batch(data_tensor_matrix[:200], mask_tensor_matrix[:200], 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The input needs to be on the form of a dataframe with a column named 'Sentence'\n",
    "Where each row consists of one sentence\n",
    "\n",
    "One can also pass an ordinary string, this method formats it for use with the model\n",
    "\"\"\"\n",
    "def check_input_format(input_data):\n",
    "    print(\"Checking input...\")\n",
    "    if isinstance(input_data, pd.DataFrame):\n",
    "        if 'Sentence' in input_data:\n",
    "            print(\"PASS\")\n",
    "            return input_data\n",
    "        else:\n",
    "            print(\"FAIL\")\n",
    "    elif isinstance(input_data, str):\n",
    "        print(\"Converting sentence to DataFrame Object\")\n",
    "        sentence_df = pd.DataFrame()\n",
    "        sentence_df['Sentence'] = [input_data]\n",
    "        return sentence_df\n",
    "    else:\n",
    "        print(\"FAIL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_elements_in_2d_matrix(matrix):\n",
    "    #Stop it from being a tensor\n",
    "    x = np.array(matrix.tolist())\n",
    "    \n",
    "    #Make it 1D\n",
    "    x = x.reshape(x.shape[0]*x.shape[1], )\n",
    "    \n",
    "    #Make it into a set\n",
    "    x = set(x)\n",
    "    \n",
    "    #Count amount of unique elements in set\n",
    "    return len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split data into train and test sets by the given ratio.\n",
    "Validation sets are not needed, those we get for free with keras models\n",
    "\"\"\"\n",
    "def split_data(percentage_to_train_on, input_data, output_data):\n",
    "    ratio = percentage_to_train_on\n",
    "\n",
    "    split = int(np.ceil(ratio*input_data.shape[0]))\n",
    "\n",
    "    train_x = input_data[:split]\n",
    "    train_y = output_data[:split]\n",
    "\n",
    "    test_x = input_data[split:]\n",
    "    test_y = output_data[split:]\n",
    "\n",
    "    return train_x, train_y, test_x, test_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_start():\n",
    "    #Load the data\n",
    "    df = pd.read_pickle(\"../data/sentence_labels\")\n",
    "\n",
    "    #Work on a subset for testing purposes\n",
    "    input_df = df[['Sentence']].head(20000).copy()\n",
    "    label_df = df[['Labels']].head(20000).copy()\n",
    "    return input_df, label_df\n",
    "\n",
    "#input_df, label_df = load_data_from_start()\n",
    "\n",
    "def load_data_from_start2():\n",
    "    #Load the data\n",
    "    sentences = pd.read_pickle(\"../data/sentence_ints\").head(100)\n",
    "    attentions = pd.read_pickle(\"../data/attention_ints\").head(100)\n",
    "    labels = pd.read_pickle(\"../data/label_ints\").head(100)\n",
    "    label_list = np.load(\"../data/label_list.npy\")\n",
    "    return sentences, attentions, labels, label_list\n",
    "\n",
    "sentences, attentions, labels, label_list = load_data_from_start2()\n",
    "\n",
    "def generate_embeddings():\n",
    "    data_tensor_matrix, mask_tensor_matrix,_ = format_sentences_for_BERT(input_df)\n",
    "    label_matrix = format_labels_for_BERT(label_df)\n",
    "    embedding_matrix = get_embeddings_with_gpu_batch(data_tensor_matrix, mask_tensor_matrix, 50)\n",
    "    \n",
    "    return embedding_matrix, label_matrix\n",
    "\n",
    "#embedding_matrix, label_matrix = generate_embeddings()\n",
    "\n",
    "def load_embeddings():\n",
    "    #np.save('../data/20000_embedding', embedding_matrix)\n",
    "    #np.save('../data/20000_label', label_matrix)\n",
    "    embedding_matrix = np.load('../data/20000_embedding.npy')\n",
    "    label_matrix = np.load('../data/20000_label.npy')\n",
    "    return embedding_matrix, label_matrix\n",
    "\n",
    "#embedding_matrix, label_matrix = load_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50030, 128)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('KB/albert-base-swedish-cased-alpha')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"KB/albert-base-swedish-cased-alpha\")\n",
    "tokenizer.add_tokens(label_list.tolist())\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_embeddings_with_gpu_batch(sentences, attentions, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "      <th>400</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>216</td>\n",
       "      <td>544</td>\n",
       "      <td>9085</td>\n",
       "      <td>72</td>\n",
       "      <td>2955</td>\n",
       "      <td>771</td>\n",
       "      <td>3711</td>\n",
       "      <td>23095</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>56</td>\n",
       "      <td>26997</td>\n",
       "      <td>2398</td>\n",
       "      <td>56</td>\n",
       "      <td>1282</td>\n",
       "      <td>1142</td>\n",
       "      <td>72</td>\n",
       "      <td>2980</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49933</td>\n",
       "      <td>8</td>\n",
       "      <td>8231</td>\n",
       "      <td>104</td>\n",
       "      <td>187</td>\n",
       "      <td>1586</td>\n",
       "      <td>11425</td>\n",
       "      <td>54</td>\n",
       "      <td>618</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>49933</td>\n",
       "      <td>8</td>\n",
       "      <td>276</td>\n",
       "      <td>56</td>\n",
       "      <td>34405</td>\n",
       "      <td>107</td>\n",
       "      <td>419</td>\n",
       "      <td>920</td>\n",
       "      <td>721</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3377</td>\n",
       "      <td>53</td>\n",
       "      <td>79</td>\n",
       "      <td>298</td>\n",
       "      <td>33</td>\n",
       "      <td>12716</td>\n",
       "      <td>49933</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>204</td>\n",
       "      <td>13013</td>\n",
       "      <td>2083</td>\n",
       "      <td>49933</td>\n",
       "      <td>8</td>\n",
       "      <td>588</td>\n",
       "      <td>100</td>\n",
       "      <td>35605</td>\n",
       "      <td>1229</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>49933</td>\n",
       "      <td>8</td>\n",
       "      <td>1045</td>\n",
       "      <td>2555</td>\n",
       "      <td>200</td>\n",
       "      <td>705</td>\n",
       "      <td>104</td>\n",
       "      <td>187</td>\n",
       "      <td>4266</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>335</td>\n",
       "      <td>34405</td>\n",
       "      <td>399</td>\n",
       "      <td>1087</td>\n",
       "      <td>4332</td>\n",
       "      <td>49933</td>\n",
       "      <td>8</td>\n",
       "      <td>132</td>\n",
       "      <td>803</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>276</td>\n",
       "      <td>33</td>\n",
       "      <td>1276</td>\n",
       "      <td>29039</td>\n",
       "      <td>93</td>\n",
       "      <td>640</td>\n",
       "      <td>1917</td>\n",
       "      <td>41</td>\n",
       "      <td>1917</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>404</td>\n",
       "      <td>37729</td>\n",
       "      <td>263</td>\n",
       "      <td>1739</td>\n",
       "      <td>79</td>\n",
       "      <td>102</td>\n",
       "      <td>54</td>\n",
       "      <td>2955</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 404 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0      1      2      3      4      5      6      7      8      9    ...  \\\n",
       "0     2    136    216    544   9085     72   2955    771   3711  23095  ...   \n",
       "1     2    136     56  26997   2398     56   1282   1142     72   2980  ...   \n",
       "2     2  49933      8   8231    104    187   1586  11425     54    618  ...   \n",
       "3     2  49933      8    276     56  34405    107    419    920    721  ...   \n",
       "4     2   3377     53     79    298     33  12716  49933      1      3  ...   \n",
       "..  ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  ...   \n",
       "95    2    204  13013   2083  49933      8    588    100  35605   1229  ...   \n",
       "96    2  49933      8   1045   2555    200    705    104    187   4266  ...   \n",
       "97    2    335  34405    399   1087   4332  49933      8    132    803  ...   \n",
       "98    2    276     33   1276  29039     93    640   1917     41   1917  ...   \n",
       "99    2    404  37729    263   1739     79    102     54   2955     72  ...   \n",
       "\n",
       "    394  395  396  397  398  399  400  401  402  403  \n",
       "0     0    0    0    0    0    0    0    0    0    0  \n",
       "1     0    0    0    0    0    0    0    0    0    0  \n",
       "2     0    0    0    0    0    0    0    0    0    0  \n",
       "3     0    0    0    0    0    0    0    0    0    0  \n",
       "4     0    0    0    0    0    0    0    0    0    0  \n",
       "..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "95    0    0    0    0    0    0    0    0    0    0  \n",
       "96    0    0    0    0    0    0    0    0    0    0  \n",
       "97    0    0    0    0    0    0    0    0    0    0  \n",
       "98    0    0    0    0    0    0    0    0    0    0  \n",
       "99    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[100 rows x 404 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/test split it\n",
    "ratio = 0.8\n",
    "train_x,train_y,test_x,test_y = split_data(ratio, embedding_matrix, label_matrix)\n",
    "\n",
    "one_hot_encoding = pd.get_dummies(train_y.reshape(-1,))\n",
    "\n",
    "#Create a dictionary key for the one-hot-encoding indices and labels\n",
    "label_dict = {}\n",
    "for i in range(one_hot_encoding.shape[1]):\n",
    "    integer = int(one_hot_encoding.columns[i])\n",
    "    label = tokenizer.decode(integer)\n",
    "    label_dict.update({i:label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I sin första reaktion på Sovjetledarens varningar deklarerade Litauens president Vytautas Landsbergis att \" nu avvisar Gorbatjov vår utsträckta hand med extremt skarpa och hämndlystna ord \" .'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.iloc[0].Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    2, 49984, 49984, 49984, 49984, 49984, 49984, 49984, 49984,\n",
       "           1, 49984,     1, 49984, 49984, 49984, 49984,     1, 49984,\n",
       "       49984, 49984, 49984, 49984, 49984, 49984, 49984, 49984, 49984,\n",
       "       49984,     3,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP]'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 50, 9) (4000, 50, 9)\n",
      "(16000, 50, 768) (4000, 50, 768)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the training data\n",
    "train_y = np.array(pd.get_dummies(train_y.reshape(-1,))).reshape(train_y.shape[0], train_y.shape[1], -1)\n",
    "test_y = np.array(pd.get_dummies(test_y.reshape(-1,))).reshape(test_y.shape[0], test_y.shape[1], -1)\n",
    "print(train_y.shape, test_y.shape)\n",
    "print(train_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199999</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7200000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1\n",
       "0        1  0\n",
       "1        1  0\n",
       "2        0  1\n",
       "3        1  0\n",
       "4        1  0\n",
       "...     .. ..\n",
       "7199995  1  0\n",
       "7199996  1  0\n",
       "7199997  1  0\n",
       "7199998  1  0\n",
       "7199999  1  0\n",
       "\n",
       "[7200000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(train_y.reshape(-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN ALBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create classification layer\n",
    "\n",
    "To ablate the fine-tuning approach, we apply the\n",
    "feature-based approach by extracting the activations from one or more layers without fine-tuning\n",
    "any parameters of BERT. These contextual embeddings are used as input to a randomly initialized two-layer 768-dimensional BiLSTM before\n",
    "the classification layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple baseline model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#input_dim = input_data.shape[1]\n",
    "#output_dim = output_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Dense(8, input_dim=input_dim, activation='relu'))\n",
    "    model.add(\n",
    "        Dense(output_dim, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Bidirectional, TimeDistributed, Dropout\n",
    "from keras.models import Model, Input\n",
    "def naive_bilstm_model():   \n",
    "    #Define the input shape. Each datapoint is a sentence consisting of seqlength words, each word 784dims\n",
    "    input = Input(shape=(train_x.shape[1], train_x.shape[2]))\n",
    "    # Pass it through a bidirectional lstm\n",
    "    model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(input)\n",
    "            \n",
    "    # add a timedistributed layer\n",
    "    out = TimeDistributed(Dense(train_y.shape[2], activation=\"softmax\"))(model)  # softmax output layer\n",
    "    \n",
    "    model = Model(input, out)\n",
    "    \n",
    "    # Compile it\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 50, 768)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 50, 200)           695200    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 50, 9)             1809      \n",
      "=================================================================\n",
      "Total params: 697,009\n",
      "Trainable params: 697,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 14400 samples, validate on 1600 samples\n",
      "Epoch 1/1\n",
      "14400/14400 [==============================] - 18s 1ms/step - loss: 0.2120 - accuracy: 0.9340 - val_loss: 0.1080 - val_accuracy: 0.9630\n",
      "\n",
      "history dict: dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# Train the model, setting aside 10% data for validation\n",
    "model = naive_bilstm_model()\n",
    "def train_model():\n",
    "    history = model.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "        epochs=1,\n",
    "        batch_size=50,\n",
    "        validation_split=0.1)\n",
    "    return history\n",
    "\n",
    "history = train_model()\n",
    "print('\\nhistory dict:', history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking input...\n",
      "PASS\n"
     ]
    }
   ],
   "source": [
    "_,_, sentence_data = format_sentences_for_BERT(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[CLS] [CLS]\n",
      "8\n",
      "- I\n",
      "8\n",
      "- en\n",
      "8\n",
      "- ruta\n",
      "8\n",
      "- talar\n",
      "8\n",
      "- en\n",
      "8\n",
      "- kort\n",
      "8\n",
      "- rad\n",
      "8\n",
      "- på\n",
      "8\n",
      "- ryska\n",
      "8\n",
      "- om\n",
      "8\n",
      "- att\n",
      "8\n",
      "- de\n",
      "8\n",
      "- port\n",
      "8\n",
      "- ation\n",
      "8\n",
      "- har\n",
      "8\n",
      "- förekommit\n",
      "8\n",
      "- ,\n",
      "8\n",
      "- en\n",
      "8\n",
      "- siff\n",
      "8\n",
      "- erk\n",
      "8\n",
      "- omb\n",
      "8\n",
      "- ination\n",
      "8\n",
      "- förklarar\n",
      "8\n",
      "- graden\n",
      "0\n",
      "<pad> av\n",
      "0\n",
      "<pad> \n",
      "0\n",
      "<pad> \"\n",
      "0\n",
      "<pad> brottslighet\n",
      "0\n",
      "<pad> \n",
      "0\n",
      "<pad> \"\n",
      "0\n",
      "<pad> \n",
      "0\n",
      "<pad> .\n",
      "0\n",
      "<pad> [SEP]\n",
      "0\n",
      "<pad> <pad>\n",
      "0\n",
      "<pad> <pad>\n",
      "0\n",
      "<pad> <pad>\n",
      "0\n",
      "<pad> <pad>\n",
      "0\n",
      "<pad> <pad>\n",
      "0\n",
      "<pad> <pad>\n",
      "0\n",
      "<pad> <pad>\n",
      "0\n",
      "<pad> <pad>\n",
      "0\n",
      "<pad> <pad>\n",
      "0\n",
      "<pad> <pad>\n",
      "0\n",
      "<pad> <pad>\n",
      "0\n",
      "<pad> <pad>\n",
      "0\n",
      "<pad> <pad>\n",
      "0\n",
      "<pad> <pad>\n",
      "0\n",
      "<pad> <pad>\n",
      "0\n",
      "<pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "sentence_embedding = embedding_matrix[i]\n",
    "sentence_embedding = sentence_embedding.reshape(1, sentence_embedding.shape[0], sentence_embedding.shape[1])\n",
    "sentence_predicitons = model.predict(sentence_embedding)\n",
    "sentence_predicitons = sentence_predicitons.reshape(sentence_predicitons.shape[1], sentence_predicitons.shape[2])\n",
    "for prediction in range(sentence_predicitons.shape[0]):\n",
    "    predicted_class = np.argmax(sentence_predicitons[prediction])\n",
    "    print(predicted_class)\n",
    "    \n",
    "    predicted_class = tokenizer.decode(int(predicted_class))\n",
    "    word = tokenizer.decode(int(sentence_data['Input'].iloc[i][prediction]))\n",
    "    print(predicted_class, word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] I sin första reaktion på Sovjetledarens varningar deklarerade Litauens president Vytautas Landsbergis att \" nu avvisar Gorbatjov vår utsträckta hand med extremt skarpa och hämndlystna ord \".[SEP]<pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "sentence_tokens = sentence_data[['Input']].iloc[i]\n",
    "for token in sentence_tokens:\n",
    "    print(tokenizer.decode(token))\n",
    "\n",
    "#Get the sentence we are testing on.\n",
    "#For each token, get the prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-58f73d999be1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Classify it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'entity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'probability'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'base_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "    #Classify it\n",
    "    c = base_model.predict(n)\n",
    "    \n",
    "    cols = ['word', 'entity', 'probability']\n",
    "\n",
    "    pretty_output_df = pd.DataFrame(columns={'word', 'entity', 'probability'})\n",
    "    \n",
    "    #Start from 1 to skip the cls token\n",
    "    #Print the predictions \n",
    "    \n",
    "    predictions = c[0]\n",
    "\n",
    "    #Take the index of the most likely word. This correspond to the class\n",
    "    index = np.argmax(predictions)\n",
    "\n",
    "    #Translate this index to a label\n",
    "    #label = tokenizer.decode()\n",
    "\n",
    "    #Grab the certainity\n",
    "    certainity = predictions[index]\n",
    "    \n",
    "    pretty_output_df = pretty_output_df.append(pd.Series(['[CLS]', label_dict.get(index), certainity], index = cols), ignore_index=True)\n",
    "\n",
    "    for i in range(len(word_list)+4):\n",
    "        \n",
    "        \n",
    "        #Get the predictions for the first word, skip the cls token\n",
    "        predictions = c[i+1]\n",
    "        \n",
    "        #Take the index of the most likely word. This correspond to the class\n",
    "        index = np.argmax(predictions)\n",
    "        \n",
    "        #Translate this index to a label\n",
    "        #label = tokenizer.decode()\n",
    "        \n",
    "        #Grab the certainity\n",
    "        certainity = predictions[index]\n",
    "        \n",
    "        #Check which word this is\n",
    "        if i <len(word_list):\n",
    "            word = word_list[i]\n",
    "        else:\n",
    "            word = \"[P A D]\"\n",
    "            \n",
    "        pretty_output_df = pretty_output_df.append(pd.Series([word, label_dict.get(index), certainity], index = cols), ignore_index=True)   \n",
    "    return pretty_output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = pd.DataFrame(columns=[\"Word\", \"Prediction\"])\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_history_df(history):\n",
    "    training_df = pd.DataFrame()\n",
    "    for metric in history.history.keys():\n",
    "        training_df[metric] = history.history[metric]\n",
    "    return training_df\n",
    "\n",
    "history_df = create_history_df(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "history_df.plot(ax=ax)\n",
    "plt.ylabel('Metric')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST ALBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n# Evaluate on test data')\n",
    "results = model.evaluate(test_x, test_y)\n",
    "for i, metric in enumerate(model.metrics_names):\n",
    "    print(f\"{metric}: {results[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"En enkel mening skriven av Victor från Stockholm, i förhoppningen om att KTH skall upptäckas som en institution.\"\n",
    "x = NER(s, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(np.array([test_x[1]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "p = model.predict(np.array([X_test[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "print(\"{:14} ({:5}): {}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "for w,pred in zip(X_test[i],p[0]):\n",
    "    print(\"{:14}: {}\".format(words[w],tags[pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".thesis",
   "language": "python",
   "name": ".thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
